{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeba9ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "import re\n",
    "\n",
    "# Download required NLTK data (run once)\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('complaints.csv')\n",
    "\n",
    "# Filter to only include rows where Consumer complaint narrative is not null\n",
    "df = df[df['Consumer complaint narrative'].notna()]\n",
    "\n",
    "# Define mapping for target categories\n",
    "product_to_category = {\n",
    "    \"Credit reporting, credit repair services, or other personal consumer reports\": 0,\n",
    "    \"Debt collection\": 1,\n",
    "    \"Consumer Loan\": 2,\n",
    "    \"Mortgage\": 3\n",
    "}\n",
    "\n",
    "# Filter to only include relevant products\n",
    "df = df[df['Product'].isin(product_to_category.keys())]\n",
    "\n",
    "# Create target column\n",
    "df['target'] = df['Product'].map(product_to_category)\n",
    "\n",
    "# Drop rows where mapping failed (if any)\n",
    "df = df.dropna(subset=['target'])\n",
    "\n",
    "# EDA: Display count of complaints for each category\n",
    "category_counts = df['target'].value_counts().sort_index()\n",
    "category_names = [\"Credit reporting, repair, or other\", \"Debt collection\", \"Consumer Loan\", \"Mortgage\"]\n",
    "print(\"Count of complaints per category:\")\n",
    "for i, name in enumerate(category_names):\n",
    "    print(f\"{name}: {category_counts.get(i, 0)}\")\n",
    "\n",
    "# Create a bar chart for class distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "category_counts.plot(kind='bar')\n",
    "plt.title('Distribution of Complaints by Category')\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Number of Complaints')\n",
    "plt.xticks(ticks=range(len(category_names)), labels=category_names, rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Analyze class imbalance\n",
    "total_samples = len(df)\n",
    "imbalance_ratios = category_counts / total_samples * 100\n",
    "print(\"\\nPercentage distribution:\")\n",
    "for i, name in enumerate(category_names):\n",
    "    print(f\"{name}: {imbalance_ratios.get(i, 0):.2f}%\")\n",
    "\n",
    "print(\"\\nClass Imbalance Analysis:\")\n",
    "print(\"The dataset shows class imbalance, with some categories (e.g., Credit reporting) likely having more samples than others (e.g., Consumer Loan).\")\n",
    "print(\"This can lead to biased models favoring majority classes. We will use stratified splitting and evaluate with balanced metrics like F1-score.\")\n",
    "\n",
    "# Define features and target\n",
    "X = df['Consumer complaint narrative']\n",
    "y = df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a226a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define preprocessing function\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove punctuation and numbers\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    \n",
    "    # Tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove stop words and lemmatize\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens if token not in stop_words]\n",
    "    \n",
    "    # Join back into string\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Apply preprocessing\n",
    "X_preprocessed = X.apply(preprocess_text)\n",
    "\n",
    "print(\"Sample preprocessed text:\")\n",
    "print(X_preprocessed.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73746326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data (80/20 stratified)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_preprocessed, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "    'Multinomial Naive Bayes': MultinomialNB(),\n",
    "    'Linear SVC': LinearSVC(random_state=42, max_iter=1000)\n",
    "}\n",
    "\n",
    "# Train pipelines\n",
    "pipelines = {}\n",
    "for name, model in models.items():\n",
    "    pipeline = Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(max_features=5000, ngram_range=(1, 2))),\n",
    "        ('clf', model)\n",
    "    ])\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    pipelines[name] = pipeline\n",
    "\n",
    "print(\"Models trained successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07b9667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate models\n",
    "results = {}\n",
    "for name, pipeline in pipelines.items():\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred, target_names=category_names, output_dict=True)\n",
    "    f1_macro = report['macro avg']['f1-score']\n",
    "    \n",
    "    results[name] = {'Accuracy': accuracy, 'F1-macro': f1_macro}\n",
    "    \n",
    "    print(f\"\\n--- {name} ---\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=category_names))\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=category_names, yticklabels=category_names)\n",
    "    plt.title(f'Confusion Matrix - {name}')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Summary table\n",
    "results_df = pd.DataFrame(results).T\n",
    "print(\"\\nModel Comparison Summary:\")\n",
    "print(results_df)\n",
    "\n",
    "# Declare best model\n",
    "best_model = results_df['F1-macro'].idxmax()\n",
    "print(f\"\\nBest performing model based on F1-macro: {best_model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54eab84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create final pipeline with best model\n",
    "best_pipeline = pipelines[best_model]\n",
    "\n",
    "# Prediction function\n",
    "def predict_category(raw_text):\n",
    "    preprocessed = preprocess_text(raw_text)\n",
    "    pred = best_pipeline.predict([preprocessed])[0]\n",
    "    return category_names[pred]\n",
    "\n",
    "# Example complaints\n",
    "examples = [\n",
    "    \"My credit report has errors that are affecting my score and I can't get them fixed.\",\n",
    "    \"The debt collector is harassing me with calls about a debt I don't owe.\",\n",
    "    \"I took out a personal loan and the interest rates are higher than promised.\",\n",
    "    \"The bank is foreclosing on my home without proper notice.\"\n",
    "]\n",
    "\n",
    "print(\"Predictions on example complaints:\")\n",
    "for example in examples:\n",
    "    prediction = predict_category(example)\n",
    "    print(f\"Complaint: {example[:100]}...\")\n",
    "    print(f\"Predicted Category: {prediction}\\n\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
